> 主要参考学习资料：
> 
> 《动手学深度学习》阿斯顿·张 等 著
> 
> 【动手学深度学习 PyTorch版】哔哩哔哩@跟李牧学AI

**概述**

- 向线性神经网络中添加**隐藏层**和**激活函数**，我们得到了**多层感知机**。
- 模型的误差分为**训练误差**和**泛化误差**，缩小泛化误差是机器学习的最终目标。缩小泛化误差的技术即**正则化技术**，本章介绍了**权重衰减**和**暂退法**两种方法。
- 在训练神经网络时，**前向传播**和**反向传播**相互依赖、交替使用。
- 深层网络有**梯度消失**和**梯度爆炸**的风险，合理的**参数初始化**方案尤为重要，本章介绍了**Xavier初始化**。
- 数据集和环境的**分布偏移**为机器学习的实际运用带来困难，不同的分布偏移有不同的纠正方法。

@[TOC](目录)
# 3.1 多层感知机

## 3.1.1 隐藏层

### 1.线性模型局限性

仿射变换中的线性是一个很强的假设，例如任何特征的增大都会导致模型输出的增大或减小，这在很多例子中很不合理，也难以通过简单的预处理解决问题。

### 2.网络加入隐藏层

在网络中加入一个或多个**隐藏层**可以突破线性模型的限制，使其能处理更普遍的函数关系模型。最简单的方法是将许多全连接层堆叠在一起，每一层都输出到其上面的层，直到生成最后的输出。其中前$L-1$层看作表示，最后一层看作线性预测器。这种架构通常称为**多层感知机**：

![](https://i-blog.csdnimg.cn/direct/fc1f810c392040998d58e8c2ca4d3318.png)


使用此网络生成输出只需要实现隐藏层和输出层的计算，因此其层数为$2$。

### 3.从线性到非线性

矩阵$\boldsymbol X\in\mathbb R^{n\times d}$表示具有$n$个输入特征数量为$d$的样本的小批量。对于具有$h$个隐藏单元的单隐藏层多层感知机，用$\boldsymbol H\in\mathbb R^{n\times h}$表述隐藏层的输出，称为**隐藏表示**或**隐藏（层）变量**。隐藏层和输出层都是全连接的，因此有隐藏层权重$\boldsymbol W^{(1)}\in\mathbb R^{d\times h}$和隐藏层偏置$\boldsymbol b^{(1)}\in\mathbb R^{1\times h}$以及输出层权重$\boldsymbol W^{(2)}\in\mathbb R^{h\times q}$和输出层偏置$\boldsymbol b^{(1)}\in\mathbb R^{1\times q}$。形式上按如下方式计算单隐藏层多层感知机的输出$\boldsymbol O\in\mathbb R^{n\times q}$：

$\boldsymbol H=\boldsymbol{XW}^{(1)}+\boldsymbol b^{(1)}$

$\boldsymbol O=\boldsymbol HW^{(2)}+\boldsymbol b^{(2)}$

然而仿射函数的仿射函数本身还是仿射函数，为了发挥多层架构的潜力还需要在仿射变换之后对每个隐藏单元应用非线性的**激活函数**$\sigma$，激活函数的输出称为**激活值**：

$\boldsymbol H=\sigma(\boldsymbol{XW}^{(1)}+\boldsymbol b^{(1)})$

$\boldsymbol O=\boldsymbol HW^{(2)}+\boldsymbol b^{(2)}$

为了构建更通用的多层感知机，我们可以继续堆叠这样的隐藏层：

$\boldsymbol H^{(1)}=\sigma_1(\boldsymbol{XW}^{(1)}+\boldsymbol b^{(1)})$

$\boldsymbol H^{(2)}=\sigma_2(\boldsymbol H^{(1)}\boldsymbol W^{(2)}+\boldsymbol b^{(2)})$

### 4.通用近似定理

即使网络只有一个隐藏层，如果给定足够的神经元和正确的权重，我们就可以对任意函数建模，尽管实际应用中学习该函数是很困难的。通过使用更深而不是更广的网络，可以更容易地逼近许多函数。

## 3.1.2 激活函数

**激活函数**通过计算加权和并加上偏置来确定神经元是否应该被激活，它们将输入信号转换为输出的可微运算。

### 1.ReLU函数

**修正现行单元**（ReLU）实现简单，同时在各种预测任务中表现良好：

$\mathrm{ReLU}(x)=\max(x,0)$

![](https://i-blog.csdnimg.cn/direct/2d7b2935b6b74d458b9d57af2956c0ee.png)


ReLU函数仅保留正元素并丢弃所有负元素。当输入为负时，ReLU函数导数为$0$，当输入为正时，ReLU函数导数为$1$，当输入为$0$时，ReLU函数不可导，默认导数为$0$，但输入几乎不会为$0$。

ReLU的求导表现要么让参数消失，要么让参数通过，优化表现更好，并且缓解了以往神经网络的梯度消失问题。

ReLU有许多变体，**参数化ReLU**添加了一个线性项，即使参数是负的，某些信息也能通过：

$\mathrm{pReLU}=\max(0,x)+\alpha\min(0,x)$

### sigmoid函数

**sigmoid函数**将输入变换为区间$(0,1)$上的输出，因此也称为**挤压函数**：

$\mathrm{sigmoid}(x)=\displaystyle\frac1{1+\exp(-x)}$

![](https://i-blog.csdnimg.cn/direct/d436e0461a364f45855d809a5fd84489.png)


在想要将输出视作二元分类问题的概率时，sigmoid仍然被广泛用作输出单元上的激活函数。然而，sigmoid在隐藏层中已经较少使用，大部分时候被更简单、更容易训练的ReLU取代。

sigmoid函数的导数为：

$\displaystyle\frac{\mathrm d}{\mathrm dx}\mathrm{sigmoid}(x)=\frac{\exp(-x)}{(1+\exp(-x))^2}=\mathrm{sigmoid}(x)(1-\mathrm{sigmoid(x)})$

![](https://i-blog.csdnimg.cn/direct/644360c796614aac8f80d0ea5f97f5e2.png)


### 3.tanh函数

tanh函数将其输入压缩转换到区间$(-1,1)$上：

$\tanh(x)=\displaystyle\frac{1-\exp(-2x)}{1+\exp(-2x)}$

![](https://i-blog.csdnimg.cn/direct/0058888ed36c4531ab7ae4740e330ec7.png)


tanh函数的导数为：

$\displaystyle\frac{\mathrm d}{\mathrm dx}\tanh(x)=1-\tanh^2(x)$

![](https://i-blog.csdnimg.cn/direct/7489c9ffefd94ec8a5a1afdc854e1df6.png)


# 3.2 多层感知机的从零开始实现

继续使用Fashion-MINIST图像分类数据集：

```python
import torch  
from torch import nn  
import torchvision  
from torchvision import transforms  
import torch.utils.data as data  
import d2l  
  
batch_size = 256  
trans = transforms.ToTensor()  
minist_train = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=trans, download=True)  
minist_test = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=trans, download=True)  
train_iter = data.DataLoader(minist_train, batch_size=batch_size, shuffle=True)  
test_iter = data.DataLoader(minist_test, batch_size=batch_size, shuffle=False)
```

## 3.2.1 初始化模型参数

```python
#实现一个具有256个隐藏单元的单隐藏层多层感知机
num_inputs, num_outputs, num_hiddens = 784, 10, 256  
  
#乘0.01设置方差为0.01
W1 = nn.Parameter(torch.randn(num_inputs, num_hiddens, requires_grad=True) * 0.01)  
b1 = nn.Parameter(torch.zeros(num_hiddens, requires_grad=True))  
W2 = nn.Parameter(torch.randn(num_hiddens, num_outputs, requires_grad=True) * 0.01)  
b2 = nn.Parameter(torch.zeros(num_outputs, requires_grad=True))  
  
params = [W1, b1, W2, b2]
```

## 3.2.2 激活函数

```python
#生成一个与X形状相同的零向量再求最大值
def relu(X):  
    a = torch.zeros_like(X)  
    return torch.max(X, a)
```

## 3.2.3 模型

```python
#@表示矩阵乘法
def net(X):  
    X = X.reshape(-1, num_inputs)  
    H = relu(X@W1 + b1)  
    return (H@W2 + b2)
```

## 3.2.4 损失函数

```python
#使用交叉熵损失函数
loss = nn.CrossEntropyLoss(reduction='none')
```

## 3.2.5 训练

```python
num_epochs, lr = 10, 0.1  
updater = torch.optim.SGD(params, lr=lr)  
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, updater)  
d2l.predict_ch3(net, test_iter, 10)
```

训练过程（最后5轮）：

```
epoch 6, loss 0.429907, test accuracy 83.35%
epoch 7, loss 0.417782, test accuracy 83.87%
epoch 8, loss 0.401954, test accuracy 84.33%
epoch 9, loss 0.389241, test accuracy 84.44%
epoch 10, loss 0.379100, test accuracy 84.62%
```

预测结果：

![](https://i-blog.csdnimg.cn/direct/7d58168a6e3947bcb7c7b29025787df5.png)


# 3.3 多层感知机的简洁实现

```python
import torch  
from torch import nn  
import torchvision  
from torchvision import transforms  
import torch.utils.data as data  
import d2l  
  
batch_size = 256  
trans = transforms.ToTensor()  
minist_train = torchvision.datasets.FashionMNIST(root='./data', train=True, transform=trans, download=True)  
minist_test = torchvision.datasets.FashionMNIST(root='./data', train=False, transform=trans, download=True)  
train_iter = data.DataLoader(minist_train, batch_size=batch_size, shuffle=True)  
test_iter = data.DataLoader(minist_test, batch_size=batch_size, shuffle=False)  
  
#添加了两个全连接层并使用了ReLU激活函数
net = nn.Sequential(nn.Flatten(),  
                    nn.Linear(784, 256),  
                    nn.ReLU(),  
                    nn.Linear(256, 10))  
  
def init_weights(m):  
    if type(m) == nn.Linear:  
        nn.init.normal_(m.weight, std=0.01)  
  
net.apply(init_weights)  
  
lr, num_epochs = 0.1, 10  
loss = nn.CrossEntropyLoss(reduction='none')  
trainer = torch.optim.SGD(net.parameters(), lr=lr)  
d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

# 3.4 模型选择、欠拟合和过拟合

机器学习的目标是发现某些**模式**，这些模式捕获到了训练集潜在的总体规律。如果成功做到了这点，即使是对以前从未遇到过的个体，模型也可以成功地评估风险。如何发现可以泛化的模式是机器学习的根本问题，其困难在于训练模型的样本有限。

将模型在训练数据上拟合得比在潜在分布中更接近的现象称为**过拟合**，用于对抗过拟合的技术称为**正则化**。

## 3.4.1 训练误差和泛化误差

**训练误差**指模型在训练数据集上计算得到的误差，**泛化误差**指模型应用在同样从原始样本的分布中抽取的无限多的数据样本时，模型误差的期望。泛化误差不能准确计算，只能将模型应用于一个独立的测试集来估计。

影响泛化误差的其中两个因素：

- 训练数据和测试数据的抽取是否遵循独立同分布假设。
- 模型复杂性，包括可调整参数的数量、参数的取值范围、训练样本的数量等。

当训练误差和泛化误差都很大，但它们之间的差距很小，我们有理由相信可以用一个更复杂的模型减小训练误差，这种现象称为**欠拟合**。当训练误差远小于泛化误差，则表明严重的过拟合。

## 3.4.2 模型选择

为了确定候选模型中的最佳模型，我们通常会使用验证集。

### 1.验证集

原则上在确定所有超参数之前，我们不希望使用测试集。如果我们在模型选择过程中使用测试数据，可能会有过拟合测试数据的风险。但我们也不能仅依靠训练数据选择模型，因为无法估计训练数据的泛化误差。常见的解决方法是将数据分成$3$份，除了训练数据集和测试数据集，再增加一个**验证数据集**用于开发阶段的调参和模型选择，而测试数据集作为最终评估依据。

### 2.K折交叉验证

当训练数据稀缺时，我们可能无法提供足够的数据来构成一个合适的验证集。一个通常的解决方案是**K折交叉验证**。首先，原始训练数据被分成$K$个不重叠的子集，然后执行$K$次模型训练和验证，每次在$K-1$个子集上进行训练，并在剩余一个子集上进行验证，最后对$K$次实验的结果取平均值来估计训练误差和验证误差。

# 3.5 权重衰减

## 3.5.1 范数与权重衰减

**权重衰减**是使用最广泛的正则化技术之一，通常也称为$L_2$正则化，该技术通过函数与零的距离来度量函数的复杂度，因为在所有函数中$f=0$在某种意义上是最简单的。一种简单的度量方法是计算线性函数$f(\boldsymbol x)=\boldsymbol w^\top\boldsymbol x$中的权重向量的某个范数（如$||\boldsymbol w||^2$），要保证权重向量较小，最常用的方法是将其范数作为惩罚项添加到最小化损失中，并通过**正则化常数**$\lambda$来权衡：

$L(\boldsymbol w,b)+\displaystyle\frac\lambda 2||\boldsymbol w||^2$

$\boldsymbol w\leftarrow(1-\eta\lambda)\boldsymbol w-\displaystyle\frac\eta{|B|}\sum_{i\in B}\boldsymbol x^{(i)}(\boldsymbol w^\top\boldsymbol x^{(i)}+b-y^{(i)})$

$L_2$正则化线性模型构成经典的**岭回归**算法，$L_1$正则化线性回归是统计学中类似的基本模型，通常称为**套索回归**。使用$L_2$范数的一个原因是它对权重向量的大分量施加了巨大的惩罚，使得学习算法偏向大量特征上均匀分布权重的模型，在实践中对单个变量中的观测误差更为稳定。相比之下，$L_1$惩罚会导致模型将权重集中在一小部分特征上，而将其他权重清除为零，称为**特征选择**，可能适用于其他场景。

## 3.5.2 从零开始实现

为使过拟合效果更加明显，我们将问题的维数增加到$d=200$，并使用一个只包含$20$个样本的小训练集：

$y=0.05+\displaystyle\sum^d_{i=1}0.01x_i+\epsilon,\epsilon\sim N(0,0.01^2)$

```python
import torch  
from torch import nn  
import d2l  
  
n_train, n_test, num_inputs, batch_size = 20, 100, 200, 5  
true_w, true_b = torch.ones((num_inputs, 1)) * 0.01, 0.05  
train_data = d2l.synthetic_data(true_w, true_b, n_train)  
#load_array函数定义在3.3中
train_iter = d2l.load_array(train_data, batch_size)  
test_data = d2l.synthetic_data(true_w, true_b, n_test)  
test_iter = d2l.load_array(test_data, batch_size, is_train=False)

#初始化模型参数
def init_params():  
    w = torch.normal(0, 1, size=(num_inputs, 1), requires_grad=True)  
    b = torch.zeros(1, requires_grad=True)  
    return [w, b]
    
#定义L2范数惩罚
def l2_penalty(w):  
    return torch.sum(w ** 2) / 2
    
#定义训练代码实现
def train(lambd):  
    w, b = init_params()  
    #沿用第3章中的线性模型
    net, loss = lambda X: d2l.linreg(X, w, b), d2l.squared_loss  
    num_epochs, lr = 100, 0.003  
    animator = d2l.Animator(xlabel='epochs', ylabel='loss', yscale='log', xlim=[5, num_epochs], legend=['train', 'test'])  
    for epoch in range(num_epochs):  
        for X, y in train_iter:  
            l = loss(net(X), y) + lambd * l2_penalty(w)  
            l.sum().backward()  
            d2l.sgd([w, b], lr, batch_size)  
        if (epoch + 1) % 5 == 0:  
            animator.add(epoch + 1, (d2l.evaluate_loss(net, train_iter, loss), d2l.evaluate_loss(net, test_iter, loss)))  
    plt.show()  
    print('w的L2范数是：', torch.norm(w).item())  
  
#忽略正则化直接训练
train(lambd=0)  
  
#使用权重衰减
train(lambd=3)
```

忽略正则化直接训练结果：

```
w的L2范数是： 12.5682373046875
```

![](https://i-blog.csdnimg.cn/direct/5dc159bfc6da4549a8dbe96d6afe919f.png)


训练误差有所减小，但测试误差居高不下，出现严重的过拟合。

使用权重衰减训练结果：

```
w的L2范数是： 0.35543060302734375
```

![](https://i-blog.csdnimg.cn/direct/7839de40d6264ad0b66f2b31e6e352d3.png)


训练误差减小到一定程度停止，但测试误差不断减小，符合期望。

## 3.5.3 简洁实现

要在pytorch的优化器中使用权重衰减，只需对需要权重衰减的参数配置$\texttt{\{'weight\_decay':wd\}}$：

```python
trainer = torch.optim.SGD([  
    {'params':net[0].weight,'weight_decay':wd},  
    {'params':net[0].bias}], lr=lr)
```

# 3.6 暂退法

简单性除了以较小的维度、参数的范数之外，另一种角度是平滑性，即函数不应该对其输入的微小变化敏感。经证明，具有输入噪声的训练等价于吉洪诺夫正则化，建立了“要求函数平滑”和“要求函数对输入的随机噪声具有适应性”之间的联系。

**暂退法**在前向传播过程中，计算每一内部层的同时注入噪声。对于如何注入这种噪声，一种想法是**无偏**，即在注入噪声的过程中期望保持不变。

在标准暂退法正则化中，每个中间激活值$h$以暂退概率$p$被随机变量$h'$替换：

$h'=\left\{\begin{matrix}0,&概率为p\\\displaystyle\frac h{1-p},&其他情况\end{matrix}\right.$

![](https://i-blog.csdnimg.cn/direct/63fc66f3cce44235a543d8c32dca7854.png)


暂退法在每轮训练中随机丢弃不同的节点，以减少输出层的计算对任一元素的过度依赖。而在测试中一般不会用暂退法，而是使用完整的模型。

## 3.6.1 从零开始实现

```python
import torch  
from torch import nn  
from d2l import torch as d2l  
#博主的d2l包中丢失了train_ch3函数，因此导入了自己的
import d2l1  
  
#单层暂退法函数
def dropout_layer(X, dropout):  
    assert 0 <= dropout < 1  
    #本情况所有元素被丢弃
    if dropout == 1:  
        return torch.zeros_like(X)  
    #本情况所有元素被保留
    if dropout == 0:  
        return X  
    #从均匀分布U[0,1]中抽取与神经网络维度一致的样本数
    #与p比较生成一个布尔值张量
    mask = (torch.rand(X.shape) > dropout).float()  
    #相乘后大于p被保留再除以1-p
    return mask * X / (1.0 - dropout)  
  
#设置两个隐藏层并分别分配暂退概率
num_inputs, num_outputs, num_hiddens1, num_hiddens_2 = 784, 10, 256, 256  
  
dropout1, dropout2 = 0.2, 0.5  
  
#定义一个有两个使用暂退法的隐藏层的神经网络类，激活函数采用ReLU
class Net(nn.Module):  
    def __init__(self, num_inputs, num_outputs, num_hiddens1, num_hiddens_2, is_training = True):  
        super(Net, self).__init__()  
        self.num_inputs = num_inputs  
        self.training = is_training  
        self.lin1 = nn.Linear(num_inputs, num_hiddens1)  
        self.lin2 = nn.Linear(num_hiddens1, num_hiddens_2)  
        self.lin3 = nn.Linear(num_hiddens_2, num_outputs)  
        self.relu = nn.ReLU()  
  
    def forward(self, X):  
        H1 = self.relu(self.lin1(X.reshape(-1, num_inputs)))  
        #只有在训练模型时才使用暂退法
        if self.training:  
            H1 = dropout_layer(H1, dropout1)  
        H2 = self.relu(self.lin2(H1))  
        if self.training:  
            H2 = dropout_layer(H2, dropout2)  
        out = self.lin3(H2)  
        return out  
  
net = Net(num_inputs, num_outputs, num_hiddens1, num_hiddens_2)  
  
num_epochs, lr, batch_size = 10, 0.5, 256  
loss = nn.CrossEntropyLoss(reduction='none')  
train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)  
trainer = torch.optim.SGD(net.parameters(), lr=lr)  
d2l1.train_ch3(net, train_iter, test_iter, loss, num_epochs, trainer)
```

运行结果：

![](https://i-blog.csdnimg.cn/direct/35877b34c9424a2ab63aa7f8c17ec650.png)


## 3.6.2 简洁实现

要在pytorch的Sequential实例中使用暂退法，只需在需要暂退的隐藏层后添加$\texttt{nn.Dropout(暂退概率)}$：

```python
net = nn.Sequential(nn.Flatten(),  
                    nn.Linear(784, 256),  
                    nn.ReLU(),  
                    nn.Dropout(dropout1),  
                    nn.Linear(256, 256),  
                    nn.ReLU(),  
                    nn.Dropout(dropout2),  
                    nn.Linear(256, 10))
```

# 3.7 前向传播、反向传播和计算图

## 3.7.1 前向传播

**前向传播**指按顺序（从输入层到输出层）计算和存储神经网络中每层的结果。

以一个不含偏置项的单隐藏层神经网络机制为例，假设输入样本是$\boldsymbol x\in\mathbb R^d$，则中间变量为：

$\boldsymbol z=\boldsymbol W^{(1)}\boldsymbol x$

其中$\boldsymbol W^{(1)}\in\mathbb R^{h\times d}$是隐藏层的权重参数。将中间变量$\boldsymbol z\in\mathbb R^h$通过激活函数$\phi$后，得到隐藏层激活向量：

$\boldsymbol h=\phi(\boldsymbol z)$

假设输出层的参数只有权重$\boldsymbol W^{(2)}\in\mathbb R^{q\times h}$，则输出层变量为：

$\boldsymbol o=\boldsymbol W^{(2)}\boldsymbol h$

假设损失函数为$l$，样本标签为$y$，则单个数据样本的损失项为：

$L=l(\boldsymbol o,y)$

根据$L_2$正则化的定义，给定超参数$\lambda$，正则化项为：

$s=\displaystyle\frac\lambda2(||\boldsymbol W^{(1)}||^2_F+||\boldsymbol W^{(2)}||^2_F)$

最后，模型在给定数据样本上的正则化损失为：

$J=L+s$

$J$在之后被称为**目标函数**。

绘制**计算图**有助于可视化计算中运算符和变量的依赖关系，如下是上述网络前向传播的计算图：

![](https://i-blog.csdnimg.cn/direct/6372b4342f93466694c8d24a5e12e415.png)


其中正方形表示变量，圆圈表示运算符，左下角表示输入，右上角表示输出。

## 3.7.2 反向传播

**反向传播**指计算神经网络参数梯度的方法。该方法根据链式法则，按相反的顺序从输出层到输入层遍历网络，存储了计算某些参数梯度时所需的任何中间变量（偏导数）。假设有函数$\boldsymbol Y=f(\boldsymbol X)$和$\boldsymbol Z=g(\boldsymbol Y)$，根据链式法则，$\boldsymbol Z$关于$\boldsymbol X$的导数为：

$\displaystyle\frac{\partial\boldsymbol Z}{\partial\boldsymbol X}=\mathrm{prod}\left(\frac{\partial\boldsymbol Z}{\partial\boldsymbol Y},\frac{\partial\boldsymbol Y}{\partial\boldsymbol X}\right)$

其中prod运算符在执行必要的操作后（如转置和交换输入位置）后将其参数相乘。

以前向传播中的神经网络为例，反向传播的目的是计算梯度$\partial J/\partial\boldsymbol W^{(1)}$和$\partial J/\partial\boldsymbol W^{(2)}$。第一步是计算目标函数$J=L+s$关于损失项$L$和正则化项$s$的梯度：

$\displaystyle\frac{\partial J}{\partial L}=1,\frac{\partial J}{\partial s}=1$

则目标函数关于输出层变量$\boldsymbol o$的梯度：

$\displaystyle\frac{\partial J}{\partial\boldsymbol o}=\mathrm{prod}\left(\frac{\partial J}{\partial L},\frac{\partial L}{\partial\boldsymbol o}\right)=\frac{\partial L}{\partial\boldsymbol o}\in\mathbb R^q$

然后计算正则化项关于两个参数的梯度：

$\displaystyle\frac{\partial s}{\partial\boldsymbol W^{(1)}}=\lambda\boldsymbol W^{(1)},\frac{\partial s}{\partial\boldsymbol W^{(2)}}=\lambda\boldsymbol W^{(2)}$

现在可以计算最接近输出层模型参数的梯度：

$\displaystyle\frac{\partial J}{\partial\boldsymbol W^{(2)}}=\mathrm{prod}\left(\frac{\partial J}{\partial\boldsymbol o},\frac{\partial\boldsymbol o}{\partial\boldsymbol W^{(2)}}\right)+\mathrm{prod}\left(\frac{\partial J}{\partial s},\frac{\partial s}{\partial\boldsymbol W^{(2)}}\right)=\frac{\partial J}{\partial\boldsymbol o}\boldsymbol h^\top+\lambda\boldsymbol W^{(2)}$

计算关于$\boldsymbol W^{(1)}$的梯度需要继续沿着输出层到隐藏层反向传播：

$\displaystyle\frac{\partial J}{\partial\boldsymbol h}=\mathrm{prod}\left(\frac{\partial J}{\partial\boldsymbol o},\frac{\partial\boldsymbol o}{\partial\boldsymbol h}\right)=\boldsymbol W^{(2)\top}\frac{\partial J}{\partial\boldsymbol o}$

由于激活函数$\phi$按元素计算，计算中间变量$\boldsymbol z$的梯度需要使用按元素乘法运算符$\odot$：

$\displaystyle\frac{\partial J}{\partial\boldsymbol z}=\mathrm{prod}\left(\frac{\partial J}{\partial\boldsymbol h},\frac{\partial\boldsymbol h}{\partial\boldsymbol z}\right)=\boldsymbol W^{(2)\top}\frac{\partial J}{\partial\boldsymbol h}\odot\phi'(\boldsymbol z)$

最后得到最接近输入层模型参数的梯度：

$\displaystyle\frac{\partial J}{\partial\boldsymbol W^{(1)}}=\mathrm{prod}\left(\frac{\partial J}{\partial\boldsymbol z},\frac{\partial\boldsymbol z}{\partial\boldsymbol W^{(1)}}\right)+\mathrm{prod}\left(\frac{\partial J}{\partial s},\frac{\partial s}{\partial\boldsymbol W^{(1)}}\right)=\frac{\partial J}{\partial\boldsymbol z}\boldsymbol x^\top+\lambda\boldsymbol W^{(1)}$

## 3.7.3 训练神经网络

在训练神经网络时，前向传播和反向传播相互依赖、交替使用。前向传播沿着依赖的方向遍历计算图并计算其路径上的所有变量，反向传播利用这些变量按与计算图相反的顺序计算。

反向传播保留并重复利用前向传播中存储的中间值直到反向传播完成，因此训练比预测需要更多内存。此外，中间值的大小与网络层的数量和批量的大小大致成正比，因此使用更大的批量来训练网络更容易导致内存不足。

# 3.8 数值稳定性和模型初始化

模型的参数初始化方案对保持数值稳定性至关重要，其可以决定优化算法收敛的速度有多快，而糟糕的方案可能导致梯度爆炸或梯度消失。

## 3.8.1 梯度消失和梯度爆炸

考虑一个具有$L$层、输入$\boldsymbol x$和输出$\boldsymbol o$的深层网络。每一层$l$由变换$f_l$定义，该变换的参数为权重$\boldsymbol W^{(l)}$，其隐藏变量为$\boldsymbol h^{(l)}$（令$\boldsymbol h^{(0)}=\boldsymbol x$）。则该网络可以表示为：

$\boldsymbol o=f_L\circ\cdots\circ f_1(\boldsymbol x)$

则$\boldsymbol o$关于任何一组参数$\boldsymbol W^{(l)}$的梯度为：

$\partial_{\boldsymbol W^{(l)}}\boldsymbol o=\partial_{\boldsymbol h^{(L-1)}}\boldsymbol h^{(L)}\cdots\partial_{\boldsymbol h^{(l)}}\boldsymbol h^{(l+1)}\partial_{\boldsymbol W^{(l)}}\boldsymbol h^{(l)}$

令矩阵$\boldsymbol M^{(t)}=\partial_{\boldsymbol h^{(t-1)}}\boldsymbol h^{(t)}$，梯度向量$\boldsymbol v^{(l)}=\partial_{\boldsymbol W^{(l)}}\boldsymbol h^{(l)}$，则该梯度是$L-1$个矩阵$\boldsymbol M^{(L)}\cdots\boldsymbol M^{(l+1)}$与梯度向量$\boldsymbol v^{(l)}$的乘积。若梯度值小于$1$，则多次相乘后梯度会趋近于$0$，造成**梯度消失**；若梯度值大于$1$，则多次相乘后梯度会急剧增大，造成**梯度爆炸**。

梯度消失的问题：

- 造成下溢，梯度值变成$0$，对$16$位浮点数尤为严重。
- 无论如何选择学习率，训练都没有进展。
- 底部层得到的梯度远小于顶部层，训练效果不平衡，无法让神经网络更深。

梯度爆炸的问题：

- 造成上溢，梯度值超出值域，对16位浮点数尤为严重。
- 对学习率敏感，学习率大→参数值大→梯度值大，学习率小→训练无进展，需要不断调整。

## 3.8.2 对称性

神经网络设计的另一个问题是其参数化所固有的对称性，例如对参数或同一层的单元重排列可以得到相同的函数。

假设有一个包含两个隐藏单元和一个输出单元的单隐藏层网络，将隐藏层的所有参数初始化为$\boldsymbol W^{(1)}=c$，则两个隐藏单元会产生相同的激活值送向输出单元，在基于梯度的迭代之后，它们的参数仍然完全相同，这样的迭代永远不会打破对称性，因而可能永远无法实现网络的表达力。暂退法则可以起到打破这种对称性的效果。

## 3.8.3 Xavier初始化

解决梯度消失或梯度爆炸的目标是让梯度值在合理的范围内，其中一个思路是将每层的输出和梯度都看做随机变量，并让它们的均值和方差都保持一致，即对于第$t$层的第$i$个单元，有：

$\mathbb E[h^t_i]=0,\mathrm{Var}[h^t_i]=a$

$\mathbb E\left[\displaystyle\frac{\partial l}{\partial h^t_i}\right]=0,\mathrm{Var}\left[\displaystyle\frac{\partial l}{\partial h^t_i}\right]=b$

$\forall i,t$

令第$t$层的第$i$个单元对来自第$t-1$层的第$j$个单元的输入的权重为$w_{i,j}^t$，我们作出如下人为假设：

- $w^t_{i,j}$独立同分布，那么$\mathbb E[w^t_{i,j}]=0,\mathrm{Var}[w^t_{i,j}]=\gamma_t$

- $h^{t-1}_i$独立于$w^t_{i,j}$

在没有激活函数的情况下：

$\boldsymbol h^t=\boldsymbol W^t\boldsymbol h^{t-1},\boldsymbol W^t\in\mathbb R^{n_t\times n_{t-1}}$

其中$n_t$表示第$t$层的输出维度。

基于上述假设，对于前向传播我们有：

$\mathbb E[h^t_i]=\mathbb E\displaystyle\left[\sum_jw_{i,j}^th_j^{t-1}\right]=\sum_j\mathbb E[w_{i,j}^t]\mathbb E[h_j^{t-1}]=0$

$\mathrm{Var}[h^t_i]=\mathbb E[(h^t_i)^2]-\mathbb E[h_i^t]^2=\mathbb E\displaystyle\left[\left(\sum_jw^t_{i,j}h^{t-1}_j\right)^2\right]$

$=\mathbb E\displaystyle\left[\sum_j(w^t_{i,j})^2(h^{t-1}_j)^2+\sum_{j\neq k}w^t_{i,j}w^t_{i,k}h^{t-1}_jh^{t-1}_k\right]$

$=\displaystyle\sum_j\mathbb E[(w^t_{i,j})^2]\mathbb E[(h^{t-1}_j)^2]$

$=\displaystyle\sum_j\mathrm{Var}[w^t_{i,j}]\mathrm{Var}[h^{t-1}_j]=n_{t-1}\gamma_t\mathrm{Var}[h_j^{t-1}]$

保持方差不变的一种方法即令每一层输入的数量和权重的方差的乘积为$1$。

与前向传播类似，反向传播由$\displaystyle\left(\frac{\partial l}{\partial\boldsymbol h^{t-1}}\right)^\top=(\boldsymbol W^t)^\top\left(\frac{\partial l}{\partial\boldsymbol h^t}\right)^\top$出发，可以得到：

$\mathrm{Var}\displaystyle\left[\frac{\partial l}{\partial h^{t-1}_i}\right]=n_t\gamma_t\mathrm{Var}\left[\frac{\partial l}{\partial h^t_j}\right]$

因此在反向传播中需令每一层输出的数量和权重的方差的乘积为$1$。

但是除非每一层的输入维度刚好等于输出维度，我们无法同时满足前向传播和反向传播推导出来的两个条件。于是Xavier在两者之间作出了如下权衡：

$\gamma_t(n_{t-1}+n_t)/2=1\Rightarrow\gamma_t=2/(n_{t-1}+n_t)$

因此对于每一层的权重，我们可以根据该层的输入和输出维度，使用以下分布初始化：

- 正态分布$N(0,\sqrt{2/(n_{t-1}+n_t)})$
- 均匀分布$U(-\sqrt{6/(n_{t-1}+n_t)},\sqrt{6/(n_{t-1}+n_t)})$

现考虑使用线性激活函数$\phi(x)=\alpha x+\beta$的情况，在前文$\boldsymbol h'=\boldsymbol W^t\boldsymbol h^{t-1}$的基础上，有$\boldsymbol h^t=\phi(h')$。相应地，我们可以求得前向传播中：

$\mathrm{Var}[h^t_i]=\alpha^2\mathrm{Var}[h'_i]-\beta^2$

为保持方差不变，只有$\phi(x)=x$。反向传播可得到同样的结果。

但现实中几乎不会用到这样的激活函数，对于常用的激活函数，我们则使用它们泰勒展开中的一次项来逼近，例如根据$\mathrm{sigmoid}$函数的泰勒展开：

$\mathrm{sigmoid}(x)=\displaystyle\frac12+\frac x4-\frac{x^3}{48}+O(x^5)$

我们可以在使用中作如下调整：

$\phi(x)=4\times\mathrm{sigmoid}(x)-2$

# 3.9 环境和分布偏移

机器学习用模型拟合各种数据集，然而数据集和真实环境往往存在分布偏移。通过将基于模型的决策引入环境，可能会破坏模型。许多失败的机器学习部署都可以追究到这种方式。

## 3.9.1 分布偏移的类型

- **协变量偏移**：输入的分布改变，而标签条件分布$P(y|\boldsymbol x)$（给定的特征属于某个标签的概率）不变。例如对猫和狗的图像分类，训练使用的数据分布都是真实的猫狗图像，而测试使用的分布都是卡通的猫狗图像。
- **标签偏移**：标签的分布改变，而类别条件分布$P(\boldsymbol x|y)$（给定的标签拥有某个特征的概率）不变。例如对疾病的预测，即使不同时期的流行病不一样，我们也会根据疾病引起的症状来判断。
- **概念偏移**：标签的定义改变。例如不同地方、不同时期对某一词语的概念、某一判断的标准不一样。

## 3.9.2 分布偏移纠正

在某些情况中，模型仍能在分布偏移下正常工作。在另一些情况中，我们可以运用策略来应对这种偏移。

### 1.经验风险与实际风险

不考虑正则化，模型在训练期间都是为了让训练损失最小化：

$\underset f\min\displaystyle\frac1n\sum^n_{i=1}l(f(\boldsymbol x_i),y_i)$

其中损失函数$l$在统计学中称这一项为**经验风险**，将经验风险取平均可以用来近似**真实风险**。在抽样数据和真实数据中，抽样数据是相对稀少、离散的，而真实数据是相对稠密、连续的，因此求和形式的平均损失最终是为了近似真实数据中总体损失积分形式的期望：

$\mathbb E_{p(x,y)}[l(f(\boldsymbol x),y)]=\iint l(f(\boldsymbol x),y)p(\boldsymbol x,y)\mathrm d\boldsymbol x\mathrm dy$

### 2.协变量偏移纠正

对于协变量偏移，机器学习的观测值$\boldsymbol x_i$从源分布$q(\boldsymbol x)$而不是目标分布$p(\boldsymbol x)$中得出，但是标签条件分布保持不变，即$p(y|\boldsymbol x)=q(y|\boldsymbol x)$，于是真实风险的计算有如下纠正：

$\iint l(f(\boldsymbol x),y)p(\boldsymbol x,y)\mathrm d\boldsymbol x\mathrm dy=\iint l(f(\boldsymbol x),y)q(y|\boldsymbol x)q(\boldsymbol x)\displaystyle\frac{p(\boldsymbol x)}{q(\boldsymbol x)}\mathrm d\boldsymbol x\mathrm dy$

根据数据来自目标分布和来自源分布的概率之比，我们重新衡量每个数据样本的权重：

$\beta_i=\displaystyle\frac{p(\boldsymbol x_i)}{q(\boldsymbol x_i)}$

将该权重代回每个数据样本中，我们可以使用**加权经验风险最小化**来训练模型：

$\underset f\min\displaystyle\frac1n\sum^n_{i=1}\beta_il(f(\boldsymbol x_i),y_i)$

$\beta_i$需要估计，对此有很多种方法，在此介绍非常有效的Logistic回归方法。

Logistic回归是用于二元分类的softmax回归的一个特例，我们使用分别从$p(\boldsymbol x)$和$q(\boldsymbol x)$抽取的相同数量的样本来将它训练成一个分类器来区分从$p(\boldsymbol x)$抽样的数据和从$q(\boldsymbol x)$抽样的数据。用标签$z$将从$p$抽取的数据表示为$1$，从$q$抽取的数据表示为$-1$，则混合数据集的概率由下式给出：

$P(z=1|\boldsymbol x)=\displaystyle\frac{p(\boldsymbol x)}{p(\boldsymbol x)+q(\boldsymbol x)}$

$\displaystyle\frac{P(z=1|\boldsymbol x)}{P(z=-1|\boldsymbol x)}=\frac{p(\boldsymbol x)}{q(\boldsymbol x)}$

对于训练好的参数函数$h(x)$，根据Logistic回归计算出的$P(z=1|\boldsymbol x)=1/(1+\exp(-h(\boldsymbol x)))$有：

$\beta_i=\displaystyle\frac{1/(1+\exp(-h(\boldsymbol x_i)))}{\exp(-h(\boldsymbol x_i))/(1+\exp(-h(\boldsymbol x_i)))}=\exp(h(\boldsymbol x_i))$

### 3.标签偏移纠正

对于标签偏移，标签的分布随时间变化，即$q(y)\neq p(y)$，但是类别条件分布不变，即$q(\boldsymbol x|y)=p(\boldsymbol x|y)$，同样可以有如下纠正：

$\iint l(f(\boldsymbol x),y)p(\boldsymbol x,y)\mathrm d\boldsymbol x\mathrm dy=\iint l(f(\boldsymbol x),y)q(\boldsymbol x|y)q(y)\displaystyle\frac{p(y)}{q(y)}\mathrm d\boldsymbol x\mathrm dy$

此时需要代回的权重为标签似然比：

$\beta_i=\displaystyle\frac{p(y_i)}{q(y_i)}$

为了估计目标分布，我们首先采用基于训练数据训练的性能相当好的分类器，并使用来自训练分布的验证集计算其混淆矩阵$\boldsymbol C$。混淆矩阵的每列对应标签类别，每行对应模型的预测类别，每个元素的值$c_{ij}$是验证集中标签为$j$的样本中被模型预测为$i$的样本占比。对每列数据取平均得到平均模型输出$\mu(\hat{\boldsymbol y})$，其中第$i$个元素$\mu(\hat y_i)$是模型预测测试集中$i$标签的总预测分数。

结果表明，如果：

- 我们的分类器相当精确。
- 目标数据只包含训练数据中的类别。
- 标签偏移假设成立（最强的假设）。

则我们可以通过求解一个简单的线性系统来估计测试集（目标数据）的标签分布：

$\boldsymbol Cp(\boldsymbol y)=\mu(\hat{\boldsymbol y})$

如果分类器足够精确，则混淆矩阵$\boldsymbol C$将可逆，进而可以得到一个解：

$p(\boldsymbol y)=\boldsymbol C^{-1}\mu(\hat{\boldsymbol y})$

### 4.概念偏移纠正

概念偏移很难用原则性的方式解决，除非遇到特别极端的情况，我们通常使用新数据更新现有的网络权重，而不是从零开始训练。
